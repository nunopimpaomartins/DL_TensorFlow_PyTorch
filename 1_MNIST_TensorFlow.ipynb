{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surgical-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-square",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "* Train a classifier with fully-connected layers only.\n",
    "* Train a classifier with convolutions only.\n",
    "* Train a classifier with convolutions and fully-connected layers.\n",
    "* Train a denoising network. Note, you have to create some noisy observations first ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "trying-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your own path ;)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rocky-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ahead-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-going",
   "metadata": {},
   "source": [
    "## train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thermal-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.title(y_train[0].item());\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_train[1000])\n",
    "plt.colorbar()\n",
    "plt.title(y_train[1000].item());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-mambo",
   "metadata": {},
   "source": [
    "## test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_test[0])\n",
    "plt.colorbar()\n",
    "plt.title(y_test[0].item());\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_test[1000])\n",
    "plt.colorbar()\n",
    "plt.title(y_test[1000].item());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-graphic",
   "metadata": {},
   "source": [
    "## categorize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comprehensive-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_labels = to_categorical(y_train)\n",
    "y_test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-exclusion",
   "metadata": {},
   "source": [
    "## flatten images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "established-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*x_train.shape[2]))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*x_test.shape[2]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-priority",
   "metadata": {},
   "source": [
    "# 1. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-pleasure",
   "metadata": {},
   "source": [
    "## fully-connected network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-excitement",
   "metadata": {},
   "source": [
    "### the simple way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-airline",
   "metadata": {},
   "source": [
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.keras.models.Sequential()\n",
    "network.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input()\n",
    "dense1 = tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,))(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-locking",
   "metadata": {},
   "source": [
    "convolutions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_network = tf.keras.models.Sequential()\n",
    "conv_network.add(tf.keras.layers.Conv2D(32, (1,1), activation='relu', input_shape=(28, 28)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(32, (1,1), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-switch",
   "metadata": {},
   "source": [
    "___\n",
    "### the hard way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-barbados",
   "metadata": {},
   "source": [
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "understood-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(512)\n",
    "        self.dense2 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.nn.relu(self.dense1(x))\n",
    "        x = tf.nn.softmax(self.dense2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-remark",
   "metadata": {},
   "source": [
    "convolution only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvModel(tf.keras.Model):\n",
    "    def __init__(sefl):\n",
    "        super(MyConvModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.nn.relu(self.conv1(x))\n",
    "        x = tf.nn.softmax(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-diversity",
   "metadata": {},
   "source": [
    "# 2. Test if model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-immigration",
   "metadata": {},
   "source": [
    "the simple way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "outside-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.1014 - accuracy: 0.9725\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0938 - accuracy: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0870 - accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0809 - accuracy: 0.9783\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0751 - accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0701 - accuracy: 0.9814\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0653 - accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0612 - accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0573 - accuracy: 0.9853\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0537 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23293e0e088>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x_train, y_train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-wings",
   "metadata": {},
   "source": [
    "___\n",
    "the hard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "emerging-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "impossible-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(784, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "conditional-blogger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             multiple                  1024      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  513       \n",
      "=================================================================\n",
      "Total params: 1,537\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "complicated-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(784, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_in = x_train[0].copy()\n",
    "one_in = tf.expand_dims(one_in, axis=-1)\n",
    "print(one_in.shape)\n",
    "\n",
    "untrained = model.call(one_in)\n",
    "untrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-cleaner",
   "metadata": {},
   "source": [
    "# 3. Choose loss-function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "offshore-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "# loss = tf.keras.losses.MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "radio-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-rotation",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss=loss_function, optimizer=optimizer_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-linux",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "compact-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-aquatic",
   "metadata": {},
   "source": [
    "# 4. Write train-loop\n",
    "\n",
    "__Note:__ This time we did not set the environment variable to hide the GPU. Hence, if you have access to a GPU the model will automatically run on GPU.\n",
    "\n",
    "__PS:__ Don't forget `@tf.function` to speed-up training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "numeric-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, loss_function, optimizer_function, num_epochs):\n",
    "    @tf.function\n",
    "    def train_step(x_, y_):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_hat = model(x_, training=True)\n",
    "            loss = loss_function(y_, y_hat)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer_function.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        return loss\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        for x_, y_ in zip(x, y):\n",
    "            x_ = tf.expand_dims(x_, -1) \n",
    "            y_ = tf.expand_dims(y_, -1)\n",
    "            \n",
    "            loss = train_step(x_, y_)\n",
    "            \n",
    "            running_loss += float(loss) # cast to float\n",
    "            \n",
    "        running_loss /= len(x)\n",
    "        if e % 2 == 0:\n",
    "            running_loss /= 100.\n",
    "            print('Epoch: {:4}; Train-Loss: {}'.format(e, np.round(running_loss, 3)))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "inside-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf2a7b668314226b5d10d45622e1657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0; Train-Loss: 232.713\n",
      "Epoch:    2; Train-Loss: 232.717\n",
      "Epoch:    4; Train-Loss: 232.717\n",
      "Epoch:    6; Train-Loss: 232.717\n",
      "Epoch:    8; Train-Loss: 232.717\n"
     ]
    }
   ],
   "source": [
    "train(model, x_train, y_train, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-multimedia",
   "metadata": {},
   "source": [
    "# 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ordered-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0781 - accuracy: 0.9771\n",
      "0.07811627207584679\n",
      "0.9771\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(x=x_test, y=y_test_labels)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "supposed-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 21us/sample\n"
     ]
    }
   ],
   "source": [
    "pred = network.predict(x_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "growing-forest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "colored-rings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "max_value = max(pred[index])\n",
    "label = np.where(pred[index] == max_value)\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-basic",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "hollywood-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_small = x_test[0:100]\n",
    "y_test_small = y_test[0:100]\n",
    "y_test_labels_small = y_test_labels[0:100]\n",
    "\n",
    "for i,j in zip(x_test_small, y_test_small):\n",
    "    i = tf.expand_dims(i, -1)\n",
    "    j = tf.expand_dims(j, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "purple-belfast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Error when checking model input: expected no data, but got:', array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-6e944d2af92b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_labels_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\dltf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    494\u001b[0m       raise ValueError(\n\u001b[0;32m    495\u001b[0m           \u001b[1;34m'Error when checking model '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m           'expected no data, but got:', data)\n\u001b[0m\u001b[0;32m    497\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Error when checking model input: expected no data, but got:', array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]))"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test_small, y_test_labels_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
